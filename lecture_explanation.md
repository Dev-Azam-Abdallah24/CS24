


---

#### **البحث غير المستنير (Uninformed Search) (شرائح 28-48)**

هذا القسم يتناول استراتيجيات البحث التي لا تستخدم أي معلومات إضافية عن الهدف، أي أنها لا تعرف مدى قربها من الهدف. تعتمد فقط على هيكل الشجرة.

*   **شريحة 28: البحث غير المستنير (Uninformed Search)**
    *   **المحتوى:** تعرف استراتيجيات البحث غير المستنير بأنها تلك التي لا تستخدم أي معلومات عن الهدف (goal state) أثناء البحث. هي طرق عامة يمكن تطبيقها على أي مشكلة بحث.
    *   **الشرح:** هذه الخوارزميات لا تعرف ما إذا كانت العقدة التي تستكشفها أقرب إلى الهدف أم أبعد. هي فقط تتبع قواعد محددة لتوسيع العقد. تشمل هذه الاستراتيجيات: البحث في العمق أولاً (DFS)، البحث في العرض أولاً (BFS)، البحث الموحد التكلفة (UCS)، والبحث في العمق المحدود (DLS)، والبحث التكراري المتعمق (IDS).

*   **شريحة 29: البحث في العرض أولاً (Breadth-First Search - BFS)**
    *   **المحتوى:** خوارزمية BFS تقوم بتوسيع جميع العقد في مستوى معين قبل الانتقال إلى المستوى التالي. تستخدم قائمة انتظار (FIFO queue) لإدارة العقد التي سيتم توسيعها.
    *   **الشرح:** تبدأ من العقدة الجذرية، ثم تستكشف جميع جيرانها، ثم جميع جيران جيرانها، وهكذا. هذا يضمن إيجاد أقصر مسار (من حيث عدد الخطوات) إذا كانت تكلفة كل خطوة متساوية (1).
    *   **مثال:** في مشكلة رومانيا، إذا بدأت من Arad، ستزور جميع المدن المتصلة بـ Arad مباشرة أولاً، ثم جميع المدن المتصلة بالمدن التي زرتها للتو، وهكذا.

*   **شريحة 30: مثال على BFS (BFS Example)**
    *   **المحتوى:** يوضح بصرياً كيفية عمل BFS. تبدأ من S، ثم تستكشف A, B، ثم C, D, E, F، وهكذا.
    *   **الشرح:** الرسم البياني يوضح أن العقد يتم توسيعها حسب عمقها. العقدة S (العمق 0)، ثم A, B (العمق 1)، ثم C, D, E, F (العمق 2).

*   **شريحة 31: خصائص BFS (Properties of BFS)**
    *   **الاكتمال (Completeness):** نعم، إذا كان هناك حل، فستجده (بشرط أن يكون عامل التفرع b محدوداً).
    *   **المثالية (Optimality):** نعم، إذا كانت تكلفة كل خطوة متساوية (1)، فإنها تجد أقصر مسار. إذا كانت التكاليف مختلفة، فقد لا تكون مثالية.
    *   **تعقيد الوقت (Time complexity):** `O(b^d)` حيث `b` هو عامل التفرع و `d` هو عمق الحل. هذا يعني أنها يمكن أن تكون بطيئة جداً للمشاكل الكبيرة.
    *   **تعقيد المساحة (Space complexity):** `O(b^d)` أيضاً، لأنها تحتاج لتخزين جميع العقد في المستوى الحالي في الذاكرة. هذه هي مشكلتها الرئيسية.
    *   **الشرح:** المشكلة الأكبر في BFS هي متطلبات الذاكرة الهائلة. حتى للمشاكل ذات العمق الصغير، يمكن أن تنفد الذاكرة بسرعة.

*   **شريحة 32: البحث الموحد التكلفة (Uniform-Cost Search - UCS)**
    *   **المحتوى:** خوارزمية UCS توسع العقدة ذات التكلفة التراكمية الأقل أولاً. تستخدم قائمة أولويات (priority queue) لإدارة العقد، حيث تكون الأولوية للعقدة ذات تكلفة المسار الأقل من البداية.
    *   **الشرح:** هذه الخوارزمية هي تعميم لـ BFS. إذا كانت تكلفة كل خطوة متساوية، فإن UCS تتصرف مثل BFS. لكنها مثالية حتى لو كانت تكاليف الخطوات مختلفة. تضمن إيجاد المسار الأقل تكلفة.
    *   **مثال:** في مشكلة رومانيا، إذا كانت تكاليف الطرق مختلفة، فإن UCS ستختار دائماً الطريق الأقل تكلفة حتى تصل إلى بوخارست.

*   **شريحة 33: خصائص UCS (Properties of UCS)**
    *   **الاكتمال (Completeness):** نعم، إذا كانت تكلفة كل خطوة موجبة (غير صفرية) ومحدودة.
    *   **المثالية (Optimality):** نعم، تجد الحل الأقل تكلفة.
    *   **تعقيد الوقت (Time complexity):** `O(b^(C*/ε))` حيث `C*` هي تكلفة الحل الأمثل و `ε` هي الحد الأدنى لتكلفة الخطوة. يمكن أن تكون أسوأ من BFS في بعض الحالات.
    *   **تعقيد المساحة (Space complexity):** `O(b^(C*/ε))` أيضاً، تعاني من نفس مشكلة الذاكرة مثل BFS.
    *   **الشرح:** UCS هي الخيار الأفضل عندما تكون تكاليف الخطوات مختلفة وتريد المسار الأقل تكلفة. لكنها لا تزال تعاني من مشكلة الذاكرة.

*   **شريحة 34: البحث في العمق أولاً (Depth-First Search - DFS)**
    *   **المحتوى:** خوارزمية DFS تستكشف أعمق مسار ممكن أولاً قبل التراجع (backtracking) واستكشاف مسارات أخرى. تستخدم مكدس (LIFO stack) لإدارة العقد.
    *   **الشرح:** تبدأ من العقدة الجذرية، ثم تختار أحد أبنائها وتستكشفه إلى أقصى عمق ممكن. إذا وصلت إلى عقدة طرفية (leaf node) وليست هي الهدف، تتراجع وتختار مساراً آخر. هذه الخوارزمية موفرة للذاكرة.
    *   **مثال:** في مشكلة رومانيا، قد تذهب من Arad إلى Sibiu، ثم إلى Fagaras، ثم إلى Bucharest. إذا لم يكن Bucharest هو الهدف، تتراجع إلى Fagaras وتختار مساراً آخر (إن وجد).

*   **شريحة 35: مثال على DFS (DFS Example)**
    *   **المحتوى:** يوضح بصرياً كيفية عمل DFS. تبدأ من S، ثم A، ثم C، ثم تتراجع إذا لم يكن C هو الهدف، ثم D، وهكذا.
    *   **الشرح:** الرسم البياني يوضح أن DFS تستكشف عمودياً أولاً. لاحظ كيف يمكن أن تذهب عميقاً جداً في مسار واحد قبل أن تعود.

*   **شريحة 36: خصائص DFS (Properties of DFS)**
    *   **الاكتمال (Completeness):** لا، إذا كان هناك مسارات لا نهائية أو دورات، فقد لا تجد الحل أبداً.
    *   **المثالية (Optimality):** لا، قد تجد حلاً ولكنه ليس الأقل تكلفة.
    *   **تعقيد الوقت (Time complexity):** `O(b^m)` حيث `m` هو أقصى عمق في الشجرة. يمكن أن تكون كبيرة جداً.
    *   **تعقيد المساحة (Space complexity):** `O(bm)`، وهي أفضل بكثير من BFS و UCS. هذه هي ميزتها الرئيسية.
    *   **الشرح:** DFS مفيدة عندما تكون الذاكرة محدودة. لكنها خطيرة إذا كانت الشجرة تحتوي على مسارات لا نهائية أو دورات، وقد لا تجد الحل أو تجد حلاً غير أمثل.

*   **شريحة 37: البحث في العمق المحدود (Depth-Limited Search - DLS)**
    *   **المحتوى:** هي نسخة من DFS مع حد أقصى للعمق `l`. لا تستكشف أي عقدة أعمق من `l`.
    *   **الشرح:** هذه الخوارزمية تحل مشكلة عدم اكتمال DFS في حالة المسارات اللانهائية. إذا كان الحل موجوداً ضمن العمق `l`، فستجده. لكن إذا كان الحل أعمق من `l`، فلن تجده.
    *   **مثال:** إذا كان الهدف على عمق 5، وحددت `l=3`، فلن تجد الحل. إذا كان `l=7`، فستجده.

*   **شريحة 38: خصائص DLS (Properties of DLS)**
    *   **الاكتمال (Completeness):** لا، إذا كان الحل أعمق من `l`.
    *   **المثالية (Optimality):** لا، قد تجد حلاً ولكنه ليس الأقل تكلفة.
    *   **تعقيد الوقت (Time complexity):** `O(b^l)`.
    *   **تعقيد المساحة (Space complexity):** `O(bl)`.
    *   **الشرح:** DLS مفيدة عندما تعرف تقريباً العمق الذي يوجد فيه الحل. لكن اختيار `l` الصحيح أمر حاسم.

*   **شريحة 39: البحث التكراري المتعمق (Iterative Deepening Search - IDS)**
    *   **المحتوى:** تجمع بين مزايا BFS (الاكتمال والمثالية) و DFS (كفاءة الذاكرة). تقوم بتشغيل DLS بشكل متكرر، مع زيادة حد العمق `l` في كل مرة (0, 1, 2, ...).
    *   **الشرح:** تبدأ بـ DLS(l=0)، ثم DLS(l=1)، وهكذا. في كل تكرار، تستكشف الشجرة بعمق أكبر. على الرغم من أنها تعيد استكشاف العقد عدة مرات، إلا أنها فعالة بشكل مدهش.
    *   **مثال:** تبحث عن الهدف في العمق 0، ثم في العمق 1 (مع إعادة البحث في العمق 0)، ثم في العمق 2 (مع إعادة البحث في العمق 0 و 1)، وهكذا.

*   **شريحة 40: مثال على IDS (IDS Example)**
    *   **المحتوى:** يوضح بصرياً كيف تقوم IDS بتوسيع العقد في كل تكرار.
    *   **الشرح:** تظهر الشريحة أن العقد القريبة من الجذر يتم توسيعها عدة مرات، لكن هذا لا يؤثر بشكل كبير على الأداء الكلي لأن معظم العقد في الشجرة تكون في المستويات العميقة.

*   **شريحة 41: خصائص IDS (Properties of IDS)**
    *   **الاكتمال (Completeness):** نعم، إذا كان هناك حل.
    *   **المثالية (Optimality):** نعم، إذا كانت تكلفة كل خطوة متساوية (1).
    *   **تعقيد الوقت (Time complexity):** `O(b^d)`، وهو نفس BFS تقريباً. العقد في المستويات العليا يتم زيارتها عدة مرات، لكن العقد في المستوى `d` (حيث يوجد الحل) يتم زيارتها مرة واحدة فقط في التكرار الأخير.
    *   **تعقيد المساحة (Space complexity):** `O(bd)`، وهو نفس DFS تقريباً. هذه هي ميزتها الكبرى.
    *   **الشرح:** IDS هي خوارزمية ممتازة للبحث غير المستنير، حيث تجمع بين اكتمال ومثالية BFS مع كفاءة ذاكرة DFS. هي الخيار المفضل للعديد من مشاكل البحث غير المستنير.

*   **شريحة 42: مقارنة بين BFS و IDS (BFS vs. IDS)**
    *   **المحتوى:** جدول يقارن بين BFS و IDS من حيث تعقيد الوقت والمساحة.
    *   **الشرح:** يؤكد الجدول أن IDS هي الأفضل في معظم الحالات لأنها توفر في الذاكرة بشكل كبير دون خسارة كبيرة في الوقت مقارنة بـ BFS.

*   **شريحة 43: البحث ثنائي الاتجاه (Bidirectional Search)**
    *   **المحتوى:** تبحث في نفس الوقت من الحالة الأولية إلى الأمام ومن حالة الهدف إلى الخلف. تتوقف عندما تلتقي الشجرتان في المنتصف.
    *   **الشرح:** يمكن أن تكون أسرع بكثير من البحث أحادي الاتجاه، خاصة إذا كان عامل التفرع متساوياً في الاتجاهين. بدلاً من `b^d`، يصبح التعقيد `b^(d/2) + b^(d/2)`، وهو أصغر بكثير.
    *   **مثال:** في مشكلة رومانيا، تبدأ من Arad وتتجه نحو Bucharest، وفي نفس الوقت تبدأ من Bucharest وتتجه نحو Arad. عندما تلتقي الشجرتان في مدينة ما، يكون الحل قد وجد.

*   **شريحة 44: متى يمكن استخدام البحث ثنائي الاتجاه؟ (When can bidirectional search be used?)**
    *   **المحتوى:** يتطلب أن تكون الإجراءات 


عكسية (reversible) وأن تكون حالة الهدف معرفة بوضوح.
    *   **الشرح:** لا يمكن استخدام هذه الطريقة دائماً. على سبيل المثال، في لعبة الشطرنج، لا يمكن البحث للخلف بسهولة لأن الهدف (كش ملك) يمكن أن يتحقق بطرق عديدة جداً.

*   **شريحة 45: مقارنة استراتيجيات البحث غير المستنير (Comparison of Uninformed Search Strategies)**
    *   **المحتوى:** جدول يلخص خصائص كل استراتيجية (الاكتمال، المثالية، تعقيد الوقت، تعقيد المساحة).
    *   **الشرح:** هذا الجدول هو مرجع مهم لمقارنة الأداء. يوضح أن IDS هي الأفضل بشكل عام للبحث غير المستنير، وأن BFS مثالية ولكنها تستهلك الكثير من الذاكرة، بينما DFS سريعة في الذاكرة ولكنها غير كاملة وغير مثالية.

*   **شريحة 46: تجنب الحالات المتكررة (Avoiding Repeated States)**
    *   **المحتوى:** مشكلة الحالات المتكررة (cycles) والمسارات المتكررة. يمكن حلها عن طريق الاحتفاظ بـ 


قائمة بـ 'العقد التي تمت زيارتها' (closed list) أو 'مجموعة الاستكشاف' (explored set).
    *   **الشرح:** عندما نوسع عقدة، نتحقق مما إذا كانت الحالة المقابلة لهذه العقدة موجودة بالفعل في قائمة العقد التي تمت زيارتها. إذا كانت موجودة، فإننا نتجاهل هذه العقدة لتجنب الدورات والمسارات المتكررة. هذا يحول البحث من 'بحث شجرة' إلى 'بحث رسم بياني' (graph search).

*   **شريحة 47: بحث الرسم البياني (Graph Search)**
    *   **المحتوى:** تعديل على خوارزمية البحث في الشجرة لتجنب الحالات المتكررة. يتم الاحتفاظ بمجموعة من العقد التي تمت زيارتها (explored set). إذا كانت العقدة التي سيتم توسيعها موجودة بالفعل في هذه المجموعة، يتم تجاهلها.
    *   **الشرح:** هذا يضمن أن كل حالة في فضاء الحالة يتم زيارتها مرة واحدة فقط. هذا يحسن من كفاءة البحث بشكل كبير، خاصة في الرسوم البيانية التي تحتوي على العديد من الدورات.

*   **شريحة 48: مقارنة بين بحث الشجرة وبحث الرسم البياني (Tree Search vs. Graph Search)**
    *   **المحتوى:** يوضح أن بحث الرسم البياني أفضل في تجنب الحالات المتكررة، ولكنه يتطلب ذاكرة أكبر لتخزين 'مجموعة الاستكشاف'.
    *   **الشرح:** في معظم الحالات، يكون بحث الرسم البياني هو المفضل لأنه يمنع البحث من الوقوع في حلقات لا نهائية ويقلل من العمل المكرر. ومع ذلك، فإن تكلفة الذاكرة لتخزين جميع العقد التي تمت زيارتها يمكن أن تكون كبيرة.

---

#### **البحث المستنير (Informed Search) (شرائح 49-75)**

هذا القسم يتناول استراتيجيات البحث التي تستخدم معلومات إضافية عن الهدف (heuristics) لتوجيه البحث نحو الحل بشكل أكثر كفاءة.

*   **شريحة 49: البحث المستنير (Informed Search)**
    *   **المحتوى:** تعرف استراتيجيات البحث المستنير بأنها تلك التي تستخدم 'دالة تقديرية' (heuristic function) لتقدير مدى قرب العقدة من الهدف. هذه المعلومات تساعد في توجيه البحث بشكل أكثر ذكاءً.
    *   **الشرح:** على عكس البحث غير المستنير الذي يستكشف بشكل أعمى، تستخدم خوارزميات البحث المستنير 'معرفة المجال' (domain knowledge) لتقييم العقد وتحديد أيها يبدو أكثر واعدة للوصول إلى الهدف. هذا يمكن أن يقلل بشكل كبير من عدد العقد التي يجب استكشافها.

*   **شريحة 50: دالة التقدير (Heuristic Function)**
    *   **المحتوى:** تعرف دالة التقدير `h(n)` بأنها تقدير لتكلفة المسار من العقدة `n` إلى أقرب عقدة هدف. يجب أن تكون `h(n) = 0` إذا كانت `n` هي عقدة هدف.
    *   **الشرح:** دالة التقدير هي قلب البحث المستنير. كلما كانت دالة التقدير أفضل (أكثر دقة)، كلما كان البحث أسرع. ومع ذلك، يجب أن تكون سريعة الحساب.
    *   **مثال:** في مشكلة رومانيا، يمكن أن تكون دالة التقدير هي المسافة الجوية (straight-line distance) من المدينة الحالية إلى بوخارست. هذه المسافة هي تقدير جيد لتكلفة القيادة المتبقية.

*   **شريحة 51: البحث الجشع الأفضل أولاً (Greedy Best-First Search)**
    *   **المحتوى:** توسع العقدة التي تبدو الأقرب إلى الهدف أولاً، بناءً على دالة التقدير `h(n)`. تستخدم قائمة أولويات.
    *   **الشرح:** هذه الخوارزمية 


تتبع نهجاً جشعاً، حيث تختار دائماً العقدة التي تعتقد أنها ستوصلها إلى الهدف بأسرع وقت ممكن، دون النظر إلى التكلفة الفعلية للوصول إلى تلك العقدة من البداية.
    *   **مثال:** في مشكلة رومانيا، إذا كنت في Oradea، ودالة التقدير تقول أن Sibiu أقرب إلى Bucharest من Zerind، فستختار Sibiu حتى لو كان المسار إلى Sibiu طويلاً.

*   **شريحة 52: مثال على Greedy Best-First Search (Greedy Best-First Search Example)**
    *   **المحتوى:** يوضح بصرياً كيفية عمل Greedy Best-First Search على مشكلة رومانيا باستخدام المسافة الجوية كدالة تقدير.
    *   **الشرح:** تبدأ من Arad (h=366). توسع Arad إلى Sibiu (h=253), Timisoara (h=329), Zerind (h=374). تختار Sibiu لأنها الأقل h. ثم توسع Sibiu إلى Arad (h=366), Fagaras (h=178), Oradea (h=380), Rimnicu Vilcea (h=193). تختار Fagaras لأنها الأقل h. ثم توسع Fagaras إلى Bucharest (h=0). تم العثور على الهدف.

*   **شريحة 53: خصائص Greedy Best-First Search (Properties of Greedy Best-First Search)**
    *   **الاكتمال (Completeness):** لا، يمكن أن تعلق في حلقة لا نهائية إذا لم يتم التعامل مع الحالات المتكررة.
    *   **المثالية (Optimality):** لا، لأنها لا تأخذ في الاعتبار تكلفة المسار من البداية، فقد تجد حلاً ولكنه ليس الأقل تكلفة.
    *   **تعقيد الوقت (Time complexity):** `O(b^m)` في أسوأ الحالات، ولكن يمكن أن تكون أفضل بكثير إذا كانت دالة التقدير جيدة.
    *   **تعقيد المساحة (Space complexity):** `O(b^m)` في أسوأ الحالات، لأنها تحتاج لتخزين العقد في قائمة الأولويات.
    *   **الشرح:** هذه الخوارزمية سريعة جداً إذا كانت دالة التقدير دقيقة، ولكنها لا تضمن إيجاد الحل الأمثل.

*   **شريحة 54: خوارزمية A* (A* Search Algorithm)**
    *   **المحتوى:** تجمع بين مزايا UCS (المثالية) و Greedy Best-First Search (الكفاءة). توسع العقدة التي تقلل من `f(n) = g(n) + h(n)`، حيث `g(n)` هي تكلفة المسار من البداية إلى العقدة `n`، و `h(n)` هي تقدير تكلفة المسار من `n` إلى الهدف.
    *   **الشرح:** A* هي واحدة من أشهر وأقوى خوارزميات البحث. هي تحاول إيجاد الحل الأمثل بأقل عدد من العقد المستكشفة. `g(n)` تمثل التكلفة الفعلية المعروفة، و `h(n)` تمثل التكلفة المقدرة المتبقية. `f(n)` هي تقدير التكلفة الكلية للمسار عبر العقدة `n`.

*   **شريحة 55: مثال على A* (A* Search Example)**
    *   **المحتوى:** يوضح بصرياً كيفية عمل A* على مشكلة رومانيا.
    *   **الشرح:** تبدأ من Arad (g=0, h=366, f=366). توسع Arad إلى Sibiu (g=140, h=253, f=393), Timisoara (g=118, h=329, f=447), Zerind (g=75, h=374, f=449). تختار Sibiu لأنها الأقل f. ثم توسع Sibiu إلى Arad (g=280, h=366, f=646), Fagaras (g=239, h=178, f=417), Oradea (g=291, h=380, f=671), Rimnicu Vilcea (g=220, h=193, f=413). تختار Rimnicu Vilcea لأنها الأقل f. وهكذا تستمر حتى تصل إلى Bucharest.

*   **شريحة 56: خصائص A* (Properties of A*)**
    *   **الاكتمال (Completeness):** نعم، إذا كانت دالة التقدير متسقة (consistent) أو مقبولة (admissible) وعامل التفرع محدود.
    *   **المثالية (Optimality):** نعم، إذا كانت دالة التقدير مقبولة (admissible) (أي لا تبالغ في تقدير التكلفة الحقيقية للوصول إلى الهدف) ومتسقة (consistent) (أي أن تقدير التكلفة من عقدة إلى أخرى لا يقل عن التكلفة الفعلية بينهما).
    *   **تعقيد الوقت (Time complexity):** `O(b^d)` في أسوأ الحالات، ولكنها أفضل بكثير من البحث غير المستنير إذا كانت دالة التقدير جيدة. تعتمد بشكل كبير على جودة دالة التقدير.
    *   **تعقيد المساحة (Space complexity):** `O(b^d)` في أسوأ الحالات، لأنها تحتاج لتخزين جميع العقد في قائمة الأولويات. هذه هي مشكلتها الرئيسية.
    *   **الشرح:** A* هي الخوارزمية المفضلة للبحث المستنير عندما تكون المثالية مطلوبة. مشكلتها الرئيسية هي متطلبات الذاكرة.

*   **شريحة 57: دالة التقدير المقبولة (Admissible Heuristics)**
    *   **المحتوى:** دالة التقدير `h(n)` تكون مقبولة إذا كانت لا تبالغ أبداً في تقدير التكلفة الحقيقية للوصول إلى الهدف من العقدة `n`. أي `h(n) ≤ h*(n)` حيث `h*(n)` هي التكلفة الحقيقية.
    *   **الشرح:** هذه الخاصية ضرورية لضمان مثالية A*. إذا كانت دالة التقدير تبالغ في التقدير، فقد تتجاهل A* المسار الأمثل.
    *   **مثال:** المسافة الجوية هي دالة تقدير مقبولة لأن أقصر مسافة بين نقطتين هي الخط المستقيم، ولا يمكن أن تكون تكلفة القيادة أقل من المسافة الجوية.

*   **شريحة 58: دالة التقدير المتسقة (Consistent Heuristics)**
    *   **المحتوى:** دالة التقدير `h(n)` تكون متسقة إذا كانت تكلفة الانتقال من `n` إلى `n'` بالإضافة إلى تقدير `h(n')` لا تقل عن تقدير `h(n)`. أي `c(n, a, n') + h(n') ≥ h(n)`.
    *   **الشرح:** هذه الخاصية أقوى من القبولية وتضمن أن قيمة `f(n)` لا تتناقص على طول أي مسار. إذا كانت دالة التقدير متسقة، فإنها تكون مقبولة أيضاً.

*   **شريحة 59: بناء دوال التقدير (Constructing Heuristics)**
    *   **المحتوى:** كيف ننشئ دوال تقدير جيدة؟ إحدى الطرق هي تبسيط المشكلة الأصلية (relaxed problem) بحيث تصبح أسهل في الحل، ثم استخدام حل المشكلة المبسطة كتقدير.
    *   **الشرح:** الفكرة هي إزالة بعض القيود من المشكلة الأصلية. على سبيل المثال، في لغز 8-puzzle، يمكن تبسيط المشكلة عن طريق السماح للمربعات بالتحرك إلى أي مربع مجاور (حتى لو لم يكن فارغاً)، أو السماح للمربعات بالقفز إلى أي مكان. حل هذه المشاكل المبسطة يعطي تقديرات جيدة.

*   **شريحة 60: مثال: لغز 8-puzzle (Example: 8-puzzle)**
    *   **المحتوى:** دوال تقدير شائعة للغز 8-puzzle:
        1.  `h1`: عدد المربعات في غير مكانها (misplaced tiles).
        2.  `h2`: مجموع مسافات مانهاتن (Manhattan distances) لكل مربع من مكانه الصحيح.
    *   **الشرح:** `h1` هي دالة تقدير مقبولة ولكنها ليست قوية جداً. `h2` هي دالة تقدير أقوى وأكثر دقة، وهي أيضاً مقبولة ومتسقة.

*   **شريحة 61: مقارنة دوال التقدير (Comparing Heuristics)**
    *   **المحتوى:** كلما كانت دالة التقدير `h(n)` أقرب إلى `h*(n)` (التكلفة الحقيقية)، كلما كانت أفضل. إذا كانت `h1(n) ≤ h2(n)` لجميع العقد `n`، و `h2` لا تبالغ في التقدير، فإن `h2` تهيمن على `h1` (dominates).
    *   **الشرح:** دالة التقدير التي تهيمن على أخرى ستجعل A* تستكشف عدداً أقل من العقد. `h2` تهيمن على `h1` في لغز 8-puzzle.

*   **شريحة 62: مثال: أداء A* مع دوال تقدير مختلفة (Example: A* performance with different heuristics)**
    *   **المحتوى:** جدول يوضح عدد العقد المستكشفة بواسطة A* للغز 8-puzzle باستخدام `h1` و `h2` لمستويات صعوبة مختلفة.
    *   **الشرح:** يظهر الجدول بوضوح أن `h2` (Manhattan distance) تتفوق بشكل كبير على `h1` (misplaced tiles) في تقليل عدد العقد المستكشفة، مما يؤكد أهمية اختيار دالة تقدير جيدة.

*   **شريحة 63: البحث في العمق التكراري A* (Iterative Deepening A* - IDA*)**
    *   **المحتوى:** نسخة من A* تحل مشكلة الذاكرة عن طريق تشغيل DFS بشكل متكرر، ولكن بدلاً من حد العمق، تستخدم حداً لقيمة `f(n)`. في كل تكرار، يتم زيادة الحد الأدنى لقيمة `f`.
    *   **الشرح:** IDA* تجمع بين كفاءة الذاكرة لـ IDS ومثالية A*. هي خوارزمية ممتازة للمشاكل التي تتطلب ذاكرة كبيرة. هي لا تخزن قائمة الأولويات، بل تعيد البحث في كل مرة بحد `f` أعلى.

*   **شريحة 64: خصائص IDA* (Properties of IDA*)**
    *   **الاكتمال (Completeness):** نعم.
    *   **المثالية (Optimality):** نعم.
    *   **تعقيد الوقت (Time complexity):** `O(b^d)`، مثل A*.
    *   **تعقيد المساحة (Space complexity):** `O(bd)`، مثل DFS و IDS. هذه هي ميزتها الكبرى.
    *   **الشرح:** IDA* هي الخيار المفضل عندما تكون الذاكرة محدودة والمثالية مطلوبة.

*   **شريحة 65: البحث في التل (Hill-Climbing Search)**
    *   **المحتوى:** خوارزمية بحث محلية (local search) لا تحتفظ بمسار كامل. تتحرك دائماً نحو الحالة التي تبدو أفضل (أقل قيمة لدالة التقدير) من الحالة الحالية.
    *   **الشرح:** هذه الخوارزمية بسيطة جداً وسريعة، ولكنها تعاني من مشاكل كبيرة: يمكن أن تعلق في 


الحد الأقصى المحلي (local maxima) أو الهضاب (plateaus) أو التلال (ridges).
    *   **مثال:** تخيل أنك تحاول الوصول إلى قمة جبل في الضباب. في كل خطوة، تختار الاتجاه الذي يبدو أنه يصعد أكثر. قد تصل إلى قمة صغيرة (حد أقصى محلي) وتعتقد أنها القمة الحقيقية.

*   **شريحة 66: مشاكل Hill-Climbing (Problems with Hill-Climbing)**
    *   **المحتوى:** تشرح المشاكل الرئيسية لـ Hill-Climbing:
        *   **الحد الأقصى المحلي (Local maxima):** نقطة أعلى من جميع النقاط المجاورة ولكنها ليست النقطة الأعلى في فضاء البحث.
        *   **الهضاب (Plateaus):** منطقة مسطحة حيث جميع النقاط المجاورة لها نفس القيمة، مما يجعل من الصعب معرفة الاتجاه الذي يجب أن تسلكه.
        *   **التلال (Ridges):** سلسلة من الحد الأقصى المحلي التي يصعب التنقل فيها لأنها تتطلب خطوات متعددة في اتجاهات مختلفة.
    *   **الشرح:** هذه المشاكل تجعل Hill-Climbing غير كاملة وغير مثالية، ونادراً ما تستخدم بمفردها لحل المشاكل المعقدة.

*   **شريحة 67: المحاكاة الساخنة (Simulated Annealing)**
    *   **المحتوى:** خوارزمية بحث محلية مستوحاة من عملية التبريد البطيء للمعادن. تسمح بالتحرك نحو حالات أسوأ أحياناً لتجنب الوقوع في الحد الأقصى المحلي، مع تقليل احتمالية ذلك بمرور الوقت (مع انخفاض درجة الحرارة).
    *   **الشرح:** تبدأ بدرجة حرارة عالية (احتمالية كبيرة للتحرك نحو حالات أسوأ)، ثم تنخفض درجة الحرارة تدريجياً. هذا يسمح للخوارزمية باستكشاف فضاء البحث بشكل أوسع في البداية، ثم التركيز على التحسين في النهاية. هي خوارزمية كاملة ومثالية إذا كانت درجة الحرارة تنخفض ببطء كافٍ.

*   **شريحة 68: البحث في الشعاع (Beam Search)**
    *   **المحتوى:** نسخة معدلة من البحث الأفضل أولاً (Best-First Search) تحتفظ فقط بـ `k` من أفضل العقد في كل مستوى، وتتجاهل البقية.
    *   **الشرح:** هذه الخوارزمية تحاول تقليل متطلبات الذاكرة لـ Best-First Search. ومع ذلك، فإنها تفقد الاكتمال والمثالية لأنها قد تتجاهل المسار الأمثل إذا لم يكن ضمن أفضل `k` عقد في مرحلة مبكرة.

*   **شريحة 69: البحث في الشعاع المحلي (Local Beam Search)**
    *   **المحتوى:** نسخة أخرى من Beam Search حيث تبدأ بـ `k` حالة عشوائية، ثم في كل خطوة، تولد جميع الخلفاء لجميع الحالات `k`، ثم تختار أفضل `k` خلفاء لتكون الحالات الجديدة.
    *   **الشرح:** هذه الخوارزمية هي نوع من البحث المحلي المتوازي. هي مفيدة عندما يكون هناك العديد من الحلول الجيدة، ولكنها لا تضمن إيجاد الحل الأمثل.

*   **شريحة 70: البحث الوراثي (Genetic Algorithms)**
    *   **المحتوى:** خوارزمية بحث مستوحاة من التطور البيولوجي. تحتفظ بـ 


مجموعة من الحلول المحتملة (population)، وتطبق عليها عمليات مثل الاختيار (selection)، التهجين (crossover)، والطفرة (mutation) لتحسينها بمرور الأجيال.
    *   **الشرح:** تبدأ بمجموعة عشوائية من الحلول. الحلول الأفضل (التي تحقق الهدف بشكل أفضل) يتم اختيارها وتزاوجها (تهجين) لإنتاج حلول جديدة. يتم إدخال بعض التغييرات العشوائية (طفرة) للحفاظ على التنوع. هذه الخوارزميات مفيدة للمشاكل المعقدة التي لا يمكن حلها بالطرق التقليدية، ولكنها لا تضمن إيجاد الحل الأمثل.

*   **شريحة 71: البحث في الفضاء المستمر (Searching in Continuous Spaces)**
    *   **المحتوى:** يناقش كيفية التعامل مع مشاكل البحث التي يكون فيها فضاء الحالة مستمراً (مثل إحداثيات الروبوت) بدلاً من متقطع.
    *   **الشرح:** في الفضاءات المستمرة، لا يمكننا تعداد جميع الحالات. تتطلب هذه المشاكل تقنيات مختلفة مثل: أخذ العينات (sampling)، التحسين العددي (numerical optimization)، أو تحويل المشكلة إلى فضاء متقطع (discretization).

*   **شريحة 72: مشاكل القيود (Constraint Satisfaction Problems - CSPs)**
    *   **المحتوى:** نوع خاص من مشاكل البحث حيث يكون الهدف هو إيجاد حالة تحقق مجموعة من القيود.
    *   **الشرح:** بدلاً من البحث عن مسار، نبحث عن تعيين قيم للمتغيرات بحيث يتم استيفاء جميع القيود. أمثلة: تلوين الخرائط، جدول المواعيد، سودوكو.

*   **شريحة 73: مثال: مشكلة N-Queens (Example: N-Queens Problem)**
    *   **المحتوى:** وضع N من الملكات على رقعة شطرنج N×N بحيث لا تهاجم أي ملكة أخرى.
    *   **الشرح:** هذه مشكلة CSP كلاسيكية. المتغيرات هي مواقع الملكات، والقيود هي عدم وجود ملكتين في نفس الصف، العمود، أو القطر.

*   **شريحة 74: مقارنة بين البحث المستنير وغير المستنير (Comparison of Informed and Uninformed Search)**
    *   **المحتوى:** جدول يلخص الفروق الرئيسية بين النوعين.
    *   **الشرح:** البحث المستنير يستخدم المعرفة الإضافية (دالة التقدير) لتوجيه البحث وتقليل عدد العقد المستكشفة، مما يجعله أسرع بكثير في معظم الحالات. البحث غير المستنير لا يستخدم هذه المعرفة، وهو أبطأ ولكنه يضمن إيجاد الحل (إذا كان موجوداً) في بعض الحالات.

*   **شريحة 75: اختيار استراتيجية البحث (Choosing a Search Strategy)**
    *   **المحتوى:** يقدم إرشادات حول متى تختار كل استراتيجية.
    *   **الشرح:**
        *   **BFS:** عندما يكون عمق الحل صغيراً وتكلفة الخطوة متساوية، والذاكرة ليست مشكلة.
        *   **UCS:** عندما تكون تكلفة الخطوة مختلفة وتريد الحل الأمثل.
        *   **DFS:** عندما تكون الذاكرة محدودة ولا يهم المثالية أو الاكتمال (أو يمكنك التحكم في العمق).
        *   **IDS:** الخيار المفضل للبحث غير المستنير عندما تكون المثالية والاكتمال مهمين والذاكرة محدودة.
        *   **A*:** الخيار المفضل للبحث المستنير عندما تكون المثالية مهمة ودالة التقدير جيدة.
        *   **IDA*:** عندما تكون A* تستهلك الكثير من الذاكرة.
        *   **Greedy Best-First:** عندما تكون السرعة هي الأهم ولا يهم المثالية.

---

#### **البحث المحلي (Local Search) (شرائح 76-80)**

هذا القسم يركز على خوارزميات البحث التي لا تحتفظ بمسار كامل، بل تركز على تحسين الحل الحالي في فضاء البحث.

*   **شريحة 76: البحث المحلي (Local Search)**
    *   **المحتوى:** تعرف خوارزميات البحث المحلي بأنها تلك التي تعمل على حل واحد (أو عدد قليل من الحلول) في كل مرة، وتحاول تحسينه عن طريق الانتقال إلى حالة مجاورة أفضل. لا تحتفظ بمسار البحث.
    *   **الشرح:** هذه الخوارزميات مفيدة لمشاكل التحسين (optimization problems) حيث لا يهم المسار للوصول إلى الحل، بل يهم الحل نفسه (مثل إيجاد أفضل تكوين). هي موفرة جداً للذاكرة.

*   **شريحة 77: أنواع البحث المحلي (Types of Local Search)**
    *   **المحتوى:** تذكر بعض أنواع البحث المحلي التي تم تناولها سابقاً أو سيتم تناولها:
        *   Hill-Climbing (تم شرحها)
        *   Simulated Annealing (تم شرحها)
        *   Local Beam Search (تم شرحها)
        *   Genetic Algorithms (تم شرحها)
    *   **الشرح:** هذه الشريحة هي تذكير بأن هذه الخوارزميات تندرج تحت فئة البحث المحلي.

*   **شريحة 78: مشاكل التحسين (Optimization Problems)**
    *   **المحتوى:** تعرف مشاكل التحسين بأنها تلك التي يكون الهدف فيها هو إيجاد أفضل حالة (أقصى أو أدنى قيمة لدالة هدف) بدلاً من إيجاد مسار إلى حالة هدف.
    *   **الشرح:** العديد من المشاكل في العالم الحقيقي هي مشاكل تحسين، مثل تحسين جدول المواعيد، تصميم الدوائر، أو تحديد أفضل مسار لمركبة.

*   **شريحة 79: تطبيقات البحث المحلي (Applications of Local Search)**
    *   **المحتوى:** تذكر بعض التطبيقات العملية للبحث المحلي:
        *   جدولة المواعيد (Scheduling)
        *   تصميم الدوائر المتكاملة (VLSI layout)
        *   مشكلة البائع المتجول (Traveling Salesperson Problem - TSP)
    *   **الشرح:** هذه المشاكل غالباً ما تكون NP-hard، مما يعني أنه لا توجد خوارزميات متعددة الحدود لإيجاد الحل الأمثل، والبحث المحلي يقدم حلولاً جيدة في وقت معقول.

*   **شريحة 80: مقارنة البحث المحلي والبحث الشامل (Local Search vs. Global Search)**
    *   **المحتوى:** البحث المحلي يركز على إيجاد حلول جيدة في منطقة معينة من فضاء البحث، بينما البحث الشامل (مثل A*) يحاول استكشاف فضاء البحث بالكامل لإيجاد الحل الأمثل.
    *   **الشرح:** البحث المحلي أسرع وأقل استهلاكاً للذاكرة، ولكنه قد يقع في الحد الأقصى المحلي. البحث الشامل يضمن المثالية (إذا كانت الخوارزمية مثالية) ولكنه أبطأ ويستهلك ذاكرة أكبر.

---

#### **ملخص ومراجعة (شرائح 81-88)**

هذا القسم يقدم ملخصاً للمفاهيم الرئيسية التي تم تناولها في المحاضرة.

*   **شريحة 81: ملخص (Summary)**
    *   **المحتوى:** تلخص المكونات الأساسية لمشكلة البحث (الحالة الأولية، الإجراءات، نموذج الانتقال، اختبار الهدف، تكلفة المسار).
    *   **الشرح:** تذكير سريع بما يجب تحديده عند صياغة أي مشكلة بحث.

*   **شريحة 82: ملخص (Summary) - استراتيجيات البحث**
    *   **المحتوى:** تلخص استراتيجيات البحث غير المستنير (BFS, UCS, DFS, DLS, IDS) والمستنير (Greedy Best-First, A*, IDA*).
    *   **الشرح:** تذكير بالخوارزميات الرئيسية التي تم شرحها.

*   **شريحة 83: ملخص (Summary) - تقييم الاستراتيجيات**
    *   **المحتوى:** تلخص معايير تقييم استراتيجيات البحث (الاكتمال، المثالية، تعقيد الوقت، تعقيد المساحة).
    *   **الشرح:** تذكير بالمعايير التي يجب استخدامها لمقارنة أداء الخوارزميات.

*   **شريحة 84: ملخص (Summary) - دوال التقدير**
    *   **المحتوى:** تلخص مفهوم دالة التقدير (heuristic function) وأهميتها في البحث المستنير، وخصائصها (مقبولة، متسقة).
    *   **الشرح:** تذكير بأن جودة دالة التقدير هي مفتاح كفاءة البحث المستنير.

*   **شريحة 85: ملخص (Summary) - البحث المحلي**
    *   **المحتوى:** تلخص مفهوم البحث المحلي (Local Search) وتطبيقاته، ومشاكله (الحد الأقصى المحلي، الهضاب).
    *   **الشرح:** تذكير بأن البحث المحلي مفيد لمشاكل التحسين ولكنه لا يضمن الحل الأمثل.

*   **شريحة 86: أسئلة للمراجعة (Review Questions)**
    *   **المحتوى:** مجموعة من الأسئلة لمراجعة المفاهيم الأساسية.
    *   **الشرح:** هذه الشريحة مخصصة لمساعدة الطلاب على اختبار فهمهم للمادة.

*   **شريحة 87: المراجع (References)**
    *   **المحتوى:** تذكر المراجع المستخدمة في إعداد المحاضرة، وخاصة كتاب AIMA.
    *   **الشرح:** توضح مصادر المعلومات.

*   **شريحة 88: شكر وتقدير (Acknowledgements)**
    *   **المحتوى:** شكر للمؤلفين الأصليين للشرائح والمراجع.
    *   **الشرح:** شريحة ختامية لتقديم الشكر.

---

بهذا نكون قد انتهينا من شرح جميع الشرائح الـ 88 بالتفصيل. لقد حاولت تقديم أمثلة وشرح إضافي لكل شريحة لتعزيز الفهم.

الآن، سأقوم بتجميع هذا الشرح في ملف Markdown واحد، ثم سأنتقل إلى المرحلة التالية وهي تصميم وإنشاء ملف HTML الفخم والمتجاوب الذي طلبته.



